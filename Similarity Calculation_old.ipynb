{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import ngrams\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from unidecode import unidecode\n",
    "from collections import Counter\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(s):\n",
    "    \"\"\"\n",
    "    Tokenize a string into a list. \n",
    "    Remove punctuations, stopwords.\n",
    "    Remove accents.\n",
    "    Remove single letter, e.g. J. Smith -> Smith.\n",
    "    Use all letters in lower case.\n",
    "    \"\"\"\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    intermediate = tokenizer.tokenize(s)\n",
    "    stop = stopwords.words()\n",
    "    return [unidecode(i.lower()) for i in intermediate if i.lower() not in stop and len(i) > 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getNgrams(s, n):\n",
    "    \"\"\"\n",
    "    Get the Ngrams list from a string.\n",
    "    \"\"\"\n",
    "    return list(ngrams(tokenize(s), n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transplant from the Scala code\n",
    "\n",
    "def interSimilarity(a, b):\n",
    "    \"\"\"\n",
    "    Caluclate the intersected similarity.\n",
    "    \"\"\"\n",
    "    vec1 = Counter(a)\n",
    "    vec2 = Counter(b)\n",
    "    \n",
    "    intersection = vec1 & vec2  # min(vec1[x], vec2[x]) \n",
    "    numerator = sum(intersection.values())\n",
    "    \n",
    "    sum1 = sum(vec1.values())\n",
    "    sum2 = sum(vec2.values())\n",
    "    denominator = sum1 + sum2\n",
    "    \n",
    "    if denominator:\n",
    "            return 2 * float(numerator) / denominator\n",
    "    else:\n",
    "        return 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trigramSimilarity(s1, s2):\n",
    "    \"\"\"\n",
    "    Caluclate the intersected similarity of Trigrams.\n",
    "    \"\"\"\n",
    "    return interSimilarity(getNgrams(s1, 3), getNgrams(s2, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenSimilarity(s1, s2):\n",
    "    \"\"\"\n",
    "    Caluclate the intersected similarity of Tokens.\n",
    "    \"\"\"\n",
    "    return interSimilarity(tokenize(s1), tokenize(s2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source: https://rosettacode.org/wiki/Longest_common_subsequence\n",
    "# Change the return type\n",
    "\n",
    "def lcs(a, b):\n",
    "    \"\"\"\n",
    "    Return the list of the LCS of two lists.\n",
    "    \"\"\"\n",
    "    lengths = [[0 for j in range(len(b)+1)] for i in range(len(a)+1)]\n",
    "    # row 0 and column 0 are initialized to 0 already\n",
    "    for i, x in enumerate(a):\n",
    "        for j, y in enumerate(b):\n",
    "            if x == y:\n",
    "                lengths[i+1][j+1] = lengths[i][j] + 1\n",
    "            else:\n",
    "                lengths[i+1][j+1] = max(lengths[i+1][j], lengths[i][j+1])\n",
    "    # read the substring out from the matrix\n",
    "    result = []\n",
    "    x, y = len(a), len(b)\n",
    "    while x != 0 and y != 0:\n",
    "        if lengths[x][y] == lengths[x-1][y]:\n",
    "            x -= 1\n",
    "        elif lengths[x][y] == lengths[x][y-1]:\n",
    "            y -= 1\n",
    "        else:\n",
    "            assert a[x-1] == b[y-1]\n",
    "            result.insert(0, a[x-1])\n",
    "            x -= 1\n",
    "            y -= 1\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lcsSimilarity(s1, s2):\n",
    "    \"\"\"\n",
    "    Calculate the LCS similarity.\n",
    "    \"\"\"\n",
    "    t1 = tokenize(s1)\n",
    "    t2 = tokenize(s2)\n",
    "    minlen = min(len(t1), len(t2))\n",
    "    if minlen:\n",
    "        lcslen = len(lcs(t1, t2))\n",
    "        return lcslen / minlen\n",
    "    else:\n",
    "        return 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matchSimilarity(s1, s2):\n",
    "    \"\"\"\n",
    "    Calcualte the match similarity.\n",
    "    \"\"\"\n",
    "    if s1==s2:\n",
    "        return 1.0\n",
    "    else:\n",
    "        return 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def featureVectorBuilder(ref, seed_ref):\n",
    "    fv = dict()\n",
    "    \n",
    "    fv['authorTrigram'] = trigramSimilarity(ref['author'], seed_ref['author'])\n",
    "    fv['authorToken'] = tokenSimilarity(ref['author'], seed_ref['author'])\n",
    "    \n",
    "    fv['titleTrigram'] = trigramSimilarity(ref['title'], seed_ref['title'])\n",
    "    fv['titleToken'] = tokenSimilarity(ref['title'], seed_ref['title'])\n",
    "    \n",
    "    fv['publisherLCS'] = lcsSimilarity(ref['publisher'], seed_ref['publisher'])\n",
    "    \n",
    "    fv['yearMatch'] = matchSimilarity(ref['year'], seed_ref['year'])\n",
    "    \n",
    "    return fv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 0.8 1.0\n"
     ]
    }
   ],
   "source": [
    "a = \"Some random title and publisher\"\n",
    "b = \"title publisher\"\n",
    "\n",
    "print(trigramSimilarity(a, b), tokenSimilarity(a, b), lcsSimilarity(a, b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
